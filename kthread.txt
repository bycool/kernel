第二章:进程管理和调度
	现代操作系统能够同时运行若干个进程,如果一个系统只有一个处理器,那么在给定时段只有一个程序运行.这个时间很短,用户几乎感觉不到.则会造成同時間运行多个进程的错觉.
	这种系统管理方式引起了几个内核必须解决的问题,其中重要的如下:
		1,除非明确的要求,否则应用程序不能彼此干扰.物理内存是独立的,不能被其他程序访问或者修改.如果需要会有特殊机制实现.
		2,CPU时间必须在各种应用程序之间尽可能公平的共享,其中一些程序可能比其他程序更重要.
		3,内核必须决定为各个进程分配多长时间,何时切换下一个进程.
		4,在内核从进程A切换到进程B时,必须确保进程B的执行环境与上一次撤销其处理器资源时完全相同. (此出不能只用C语言实现.)

	2.1 进程优先级
	 进程有不同程度的重要性.进行比较粗糙的划分可以分为:实时进程,非实时进程.
		硬实时进程:有严格的时间限制,某些任务必须在指定时间内完成.  过时得到的执行结果就没有意义了.
		软实时进程:软实时进程是硬实时进程的弱化形式,景观需要快速得到结果,但是稍微晚一会儿得到执行结果,这个结果对进程还是有意义的.
		普通进程:没有特定时间约束的普通进程.

	 抢占式多任务处理:各个进程都分配到一定的时间段可以执行.时间段到期后,内核会从进程收回控制权,让一个不同的进程运行,而不考虑前一进程所执行的上一个任务.被抢占进程的运行时环境,即所有cpu寄存器的内容和页表,都会保存下来,因此其执行结果不会丢失.在该进程恢复执行时,其进程环境可以完全恢复.时间片的长度会更具进程重要性的不同而变化.

	2.2 进程生命周期
	 进程并不是可以立即运行,有时候它必须等待来自外部信号源,不受其控制的时间.
	 当调度器在进程之间切换时,必须知道系统中每个进程的状态.不应该将cpu时间分配到无事做的进程.浪费资源.
	 进程可能有如下几种状态:
		1,运行:该进程此刻在执行.
		2,等待:进程能够运行,但是没有得到许可,因为cpu分配给了另一个进程.下次调度可以选择这个进程.
		3,睡眠:进程无法运行,因为他在等待一个外部事件.调度器无法在下一次任务切换时选择此进程.
	 所有进程保存在一个进程表中,无论状态是运行,睡眠或者等待. 睡眠进程会被标记出来,调度器就知道它们无法立即运行.
	 睡眠进程会被分配到若干队列中.因此它们可在适当的时候唤醒.
	
	 抢占式多任务处理
	 linux进程管理结构中还需要另外两种进程状态选项:用户态和核心态. 这反应了现代CPU都有两种不同执行状态的事实.其中一个具有无限的权利,另一个受到各种限制.
	 进程通常都处于用户状态,只能访问自身的数据,无法干扰系统中的其他应用程序.甚至也不会注意到自身之外其他进程的存在.
	 如果进程想要访问系统数据或功能,必须切换到核心态.显然这只能在受控情况下完成,否则保护机制是多余的.
	 从用户态到核心态可以通过系统调用,第二种方法是系统中断.系统中断是自动出发,系统调用是由用户应用程序有意调用的.
	 内核的抢占调度模型建立了一个层次结构,由于判断那些进程状态可以由其他状态抢占.
		1,普通进程总是可能被抢占,甚至是有其他进程抢占.在一个重要进程变成可运行时,如编辑器接受到了等待已久的键盘键入,调度器可以决定是否立即执行该进程.
		2,如果系统处于核心态并正在处理系统调用,那么系统中的其他进程是无法夺取其cpu时间的.调度器必须等待系统调用执行结束.中断拥有最高优先级,中断可以终止系统调用.
		3,中断可以暂停处于用户状态和核心态的进程.中断拥有最高优先级,因为中断出发后需要尽快处理.

	2.3 进程表示
	 linux内核设计进程和程序的所有算法都围绕一个名为task_struct的数据结构建立.关于进程管理的方式.
	 task_struct包含了很多成员,将进程与各个子系统联系起来.
	 要弄清楚该结构中信息的数量很困难,但结构内容可以分解为各个部分:
		1,状态和执行信息,如带决信号,使用的二进制格式,进程ID等
		2,有关已经分配的虚拟内存的信息.
		3,进程身份凭证,用户ID,组ID以及权限等.
		4,使用的文件包含程序代码的二进制文件,以及所有程序处理的所有文件的文件系统信息.这些都必须保存下来.
		5,县城信息记录该进程特定于CPU的运行时间数据.
		6,在与其他应用程序协作时所需的进程时间通信有关的信息.
		7,该进程所用的信号处理程序,用来响应到来的信号.

	 2.3.1 进程类型
	  典型Unix进程包括:由二进制代码组成的应用程序,单线程,分配给应用程序的一组资源.新进程是使用fork和exec系统调用产生的.
		1,fork生成当前进程的一个相同副本,该副本称之为子进程.原进程的所有资源都以适当的方式复制到子进程.因此该系统调用之后,就有两个独立的实例.这两个实例的联系包括:同一组打开文件,同样的工作目录,内存中同样的数据等等.
		2,exec从一个可执行的二进制文件加载另一个应用程序,来代替当前运行的进程.加载一个新程序.因为exec并不创建新进程,只是使用此进程运行一个新程序.
		3,clone的工作原理和fork相同,但新进程不是独立于父进程的.而可以和其共享某些资源.可以指定需要共享和复制的资源种类.clone用于实现线程.但不完全.

	 2.3.2 命名空间
	  命名空间提供了虚拟化的一种轻量级形式,使得我们可以从不同的方面来查看运行系统的全局属性.
		1,概念
			许多资源是全局管理的.但是如果提供web主机的供应商打算想用户提供linux计算机的全部访问权限,包括root权限,传统上,这需要为每一个用户准备一台计算机.使用kvm提供的虚拟环境是一种方法,但是资源分配的不是很好.计算机的各个用户需要一个独立的内核,以及一分完整安装好的配套的用户层应用.
			命名空间提供了一天中不同的解决方案,所需资源较少.在虚拟花系统中,一台无力计算机可以运行多个内核,可能是提供并行的多个不同的操作系统.而命名空间则只使用一个内核在一台物理计算机上运作.前述的所有全局资源都通过命名空间抽象出来.可以将一组进程放进一个容器中,各个容器彼此隔离.隔离可以使容器的成员与其他容器毫无关系.但也可以通过允许容器进行一定的共享,来降低容器之间的分隔.
			本质上,命名空间创建了系统的不同视角.此前每一项全局资源都必须包装到容器数据结构中.只有资源和包含资源的命名空间结构的二元组仍然是全局唯一的.虽然给定容器内的资源是自足的,但是无法提供在容器外部具有唯一性的ID.
		命名空间的理解: 将资源分给不同的用户视角,这个用户视角来看它拥有整个计算机(内核,硬件,应用层),但是在root视角来看,它只是一个资源划分出去的组.将一些资源圈起来给这个用户用,还有其他这样的视角.这些衍生出来的子用户空间的资源会映射到一个父命名空间来管理这些子命名空间的资源.

	2.3.3 进程ID
	 unix会分配一个号码用于在其命名空间中唯一的标识他们.这个号码被称为进程ID.简称PID.用fork或clone产生的每个进程都有内核分配一个唯一的pid值.
	 1.进程ID: 每个进程除了pid之外还有其他id:
		.处于某个线程组中的所有进程都有统一的线程组ID(TGID).如果进程没有使用线程,则其pid和tgid相同.线程组中主进程被称组长.通过clone创建的所有线程的task_struct的group_leader成员都指向进程组长的task_struct实例.
		.独立进程可以合并进入进程组(使用setpgrp系统调用).进程组成员的task_struct的pgrp属性值都是相同的.和进程组组长的pid是相同的.
		.几个进程合并成一个会话.会话中所偶的进程都有相同的会话id,保存在task_struct的session成员中.sid可以使用setsid系统调用设置.
		.全局id是在内核本身和初始命名空间中的唯一id号.在系统启动期间开始的init进程即属于初始命名空间.对每个id类型,都有一个给定的全局id,保证在整个系统中是唯一的.
		.局部id属于某个特定的名空空间,不具备全局有效性.对每个id类型,它们都在所属的命名空间内部有效,但是类型相同,值也相同的id可能出现在不同的命名空间.
	 
	 2.管理pid.
		内核还需要找一个办法来管理所有命名空间内部的局部量.以及其他id.这需要几个相互关联的数据结构,以及许多辅助函数:
		.数据结构.
		 下文的id指代提到的任何进程id.在必要的情况下说明id类型.
		 一个小型的哦子系统简称为pid分配器（pid allocator）用于加速心的id的分配.内核提供辅助函数,实现通过id以及其类型查找进程的task_struct的功能.以及将id的内核表示形式和用户空间可见的数值进行转换的功能.
		 <pid_namespace.h>
		 struct pid_namespace {
			struct task_struct *child_reaper;
			int level;
			struct pid_namespace *parent;
		 }
		实际上pid分配器也需要依靠该结构的某些部分来连续生成唯一id.
		.每个pid名空空间都具有一个进程,其发挥的作用相当于全局的init进程.init进程的一个目的是对孤儿进程调用wait4.命名空间局部的init变体也必须完成该工作.child_reaper保存了指向该进程的task_struct的指针.
		.parent是指向父命名空间的指针.层次表示当前命名空间在命名空间层次结构中的深度.初始命名空间的level为0,该命名空间的子空间level为1,下一层为2,以此类推.

	  pid的管理围绕着两个数据结构展开:struct pid是内核对pid的内部表示,而struct upid则表示特定的命名空间中可见的信息.
		<pid.h>
		struct upid {
			int nr;
			struct pid_namespace( ns;
			struct hlist_node pid_chain;
		}
		struct pid {
			atomic_t count;
			struct hlist_head tasks[PIDTYPE_MAX]	//使用该pid的进程的列表.
			int level;
			struct upid numbers[1];
		}
		对于struct upid, nr表示id的数值.ns表示指向id所属的命名空间的指针.所有的upid实例都保存在一个散列表中.
		struct pid的定义首先是一个引用计数器count.tasks是一个数组,每个数组项都是一个散列表头,对应与一个id类型.一个进程可能在多个命名空间中可见,而其在各个命名空间内使用的局部id彼此不相同.level表示可以看到该进程的命名空间数目.numbers是一个upid实例的数组,每个数组项对应一个命名空间.该数组在结构末尾,只要分配更多内存便可想数组添加附加项.

		.函数
		 内核提供若干辅助函数,用于操作和扫描上面描述的数据结构.本质上内核必须完成下面两个不同的任务:
			1.给出局部数字id和对应的命名空间,查找此二元数组描述的task_struct.
			2.给出task_struct,ID类型,命名空间,取得命名空间局部的数字id.

		获得与task_struct关联的pid实例.辅助函数task_pid,task_tgid,task_pgrp和task_session分别用于缺德不同类型的ID:
		<sched.h>
		static inline struct pid *task_pid(struct task_struct *task){
			return task->pids[PIDTYPE_PID].pid;
		}
		找出进程组ID则需要使用PIDTYPE_PGID作为数组索引,但该id仍然需要从线程组组长task_struct实例获取:
		static inline struct pid *task_pgrp(struct task_struct *task){
			return task->group_leader->pids[PIDTYPE_PGID].pid;
		}
		在获得pid实例之后,从struct pid的numbers数组中的uid信息,即可获得数字id:
		kernel/pid.c
		pid_t pid_nr_ns(struct pid* pid,struct pid_namespace *ns){
			struct upid *upid;
			pid_t nr = 0;
			if(pid && ns->level <= pid->level){
				upid = &pid->number[ns->level];
				if(upid->ns = ns){
					nr = upid->nr;
				}
			}
			return nr;
		}


	
	

调度:

struct rq {
	struct task_struct {
		struct sched_class{

		}
	}
}


void scheduler_tick(void){
	struct rq *rq = cpu_rq(cpu);
	update_rq_clock(rq){
		delta = sched_clock_cpu(cpu_of(rq)) - sq->clock;
		rq->clock += delta;
		update_rq_clock_task(rq,delta);
	}
	
}





所有可运行的进程都按时间在一个红黑树中排序.等待时间最长的在最左侧.

调度器类:
enqueue_task想就绪队列添加一个新进程.在进程从睡眠状态变为可运行状态时,即发生该操作.
dequeue_task提供逆向操作,将一个进程从就绪队列去除.在进程从可运行状态切换到不可运行状态是,会发生该操作.
yield_task进程自愿放弃对处理器的控制权.
check_preempt_curr用一个新欢行动哦进程来抢占当前进程,在用wake_up_new_task唤醒新进程时,会调用该函数.
pick_next_task用于选择下一个将要运行的进程,而put_prev_task则在用另一个进程代替当前运行的进程之前调用.这两个函数负责想进程提供或撤销cup.
set_curr_task进程的调度侧略发生变化.
task_tick在每次激活周期性调度器时由调度器调用.
new_task用于建立fork系统调用和调度器之间的联系.每次心进程建立后,则用new_task同志调度器.



周期性调度器：在低分辨率定时器的每次时钟中断完成全局统计量更新后，每个cpu在软中断中执行一下操作：更新该cpu上当前进程内核态、用户态使用时间；调用该cpu上的定时器函数；启动周期性定时器（scheduler_tick）完成该cpu上任务的周期性调度工作；在支持动态定时器的系统中，可以关闭该调度器，从而进入深度睡眠过程；scheduler_tick查看当前进程是否运行太长时间，如果是，将进程的TIF_NEED_RESCHED置位，然后再中断返回时，调用schedule，进行进程切换操作

scheduler_tick 函数执行
  在cpu执行完全局统计后，每个cpu执行scheduler_tick,该函数实质上对rq->clock等进行更新后，主要对当前进程进行切换相关的考虑工作：
如果当前进程是完全公平队列中的进程：则首先根据当前就绪队列中的进程数算出一个延迟时间间隔，大概每个进程分配2ms时间，然后按照该进程在队列中的总权重中占得比例，算出它该执行的时间X，如果该进程执行物理时间超过了X，则激发延迟调度；如果没有超过X，但是红黑树就绪队列中下一个进程优先级更高，即curr->vruntime-leftmost->vruntime > X,也将延迟调度
如果当前进程是实时调度类中的进程：则如果该进程是SCHED_RR，则递减时间片[为HZ/10]，到期，插入到队列尾部，并激发延迟调度，如果是SCHED_FIFO，则什么也不做，直到该进程执行完成
延迟调度的真正调度过程在：schedule中实现，会按照调度类顺序和优先级挑选出一个最高优先级的进程执行

scheduler_tick 流程:
void scheduler_tick(void)
{
    //printk(KERN_ALERT "entry:: scheduler_tick()");
    int cpu = smp_processor_id();					//获得cpu id
    struct rq *rq = cpu_rq(cpu);					//获得该cpu就绪队列(进程就绪队列)
    struct task_struct *curr = rq->curr;			//获得当前正在进行的进程.

    sched_clock_tick();								//更新rq clock的值?

    raw_spin_lock(&rq->lock);
    update_rq_clock(rq);							//更新就绪队列的两个成员rq->clock_task，rq->clock
    update_cpu_load_active(rq);						//更新就绪队列的cpu_load[]数组。将数组中先前存储的负荷值向后移动一个位置，将当前就绪队列的负荷计入数组的第一个位置。
    curr->sched_class->task_tick(rq, curr, 0);		//实际调用task_tick_fair
    raw_spin_unlock(&rq->lock);

    perf_event_task_tick();

#ifdef CONFIG_SMP
    rq->idle_at_tick = idle_cpu(cpu);
    trigger_load_balance(rq, cpu);
#endif
}

static void task_tick_fair(struct rq *rq, struct task_struct *curr, int queued)
{
    struct cfs_rq *cfs_rq;
    struct sched_entity *se = &curr->se;

    for_each_sched_entity(se) {						//没有遍历所有以sched_entity为索引的队列#define for_each_sched_entity(se) for (; se; se = NULL),只处理当前进程的实体
        cfs_rq = cfs_rq_of(se);						//找到当前进程实体se所在的平衡队列.
        entity_tick(cfs_rq, se, queued);			//最后调用到check_preempt_tick
    }
}



static void
check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
{
    unsigned long ideal_runtime, delta_exec;

    ideal_runtime = sched_slice(cfs_rq, curr);		//理想欲运行时间
    delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;	//上次此进程运行以来的时间.(两次运行的时间间隔.)
    if (delta_exec > ideal_runtime) {				//如果当前进程此次运行时间大于理想运行时间,说明此次运行时间用尽且超了.
        resched_task(rq_of(cfs_rq)->curr);			//置位 TIF_NEED_RESCHED,等待周期调度器中断结束后,调用schedule来使得进程放弃运行.
        /*
         * The current task ran long enough, ensure it doesn't get
         * re-elected due to buddy favours.
         */
        clear_buddies(cfs_rq, curr);
        return;
    }

    /*
     * Ensure that a task that missed wakeup preemption by a
     * narrow margin doesn't have to wait for a full slice.
     * This also mitigates buddy induced latencies under load.
     */
    if (!sched_feat(WAKEUP_PREEMPT))
        return;

    if (delta_exec < sysctl_sched_min_granularity)		//sysctl_sched_min_granularity表示进程最少运行时间
        return;

    if (cfs_rq->nr_running > 1) {						//列表内还有进程可运行时
        struct sched_entity *se = __pick_first_entity(cfs_rq); 获得cfs红黑树最左进程的实体se
        s64 delta = curr->vruntime - se->vruntime;		

        if (delta < 0)			//当前进程需要运行的总时间小于另一个进程时间的时候 什么都不做,让当前进程继续运行.
            return;

        if (delta > ideal_runtime)			
            resched_task(rq_of(cfs_rq)->curr);
    }
}

scheduler_tick():
每一个cpu都有一个就绪进程队列rq,在就绪队列中有两个子队列,cfs完全公平队列,rt实时进程队列.
时钟注册一个中断,该中断引发周期调度器scheduler_tick(),在周期调度过程中,调度器先获得cpu_id,根据id获得cpu的rq进程就绪队列,取得当前运行的进程实例task_struct,然后调度类调用task_tick函数,在cfs类型的进程则用cfs调度类的task_tick函数处理(每个进程都需要指定一个在调度时处理它的调度类),在task_tick内,获得当前进程入口实例sched_entity,根据这个实例判断当前进程是否需要被调度(让出cpu),如果需要则resched_task(rq_of(cfs_rq)->curr);置位TIF_NEED_RESCHED,然后返回,等到中断结束返回后,调用schedule()进行进程切换.如果不需要调度,则在中断结束后,当前进程继续运行.



主调度器:
/*
 * __schedule() is the main scheduler function.
 */
static void __sched __schedule(void)
{
    //printk(KERN_ALERT "entry:: __sched __scheduler()");
    struct task_struct *prev, *next;
    unsigned long *switch_count;
    struct rq *rq;
    int cpu;

need_resched:
    preempt_disable();			//禁止内核抢占
    cpu = smp_processor_id();	//获得当前cpu
    rq = cpu_rq(cpu);			//获得当前cpu维护的运行队列
    rcu_note_context_switch(cpu);	//更新全局状态,标识当前cpu发生上下文的切换.
    prev = rq->curr;			//获得当前进程curr

    schedule_debug(prev);

    if (sched_feat(HRTICK))
        hrtick_clear(rq);

    raw_spin_lock_irq(&rq->lock);	//锁住当前队列.

    switch_count = &prev->nivcsw;	
    if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {
        if (unlikely(signal_pending_state(prev->state, prev))) {
            prev->state = TASK_RUNNING;
        } else {
            deactivate_task(rq, prev, DEQUEUE_SLEEP);	//从运行队列中移出
            prev->on_rq = 0;

            /*
             * If a worker went to sleep, notify and ask workqueue
             * whether it wants to wake up a task to maintain
             * concurrency.
             */
            if (prev->flags & PF_WQ_WORKER) {
                struct task_struct *to_wakeup;

                to_wakeup = wq_worker_sleeping(prev, cpu);
                if (to_wakeup)
                    try_to_wake_up_local(to_wakeup);
            }
        }
        switch_count = &prev->nvcsw;
    }

    pre_schedule(rq, prev);

    if (unlikely(!rq->nr_running))
        idle_balance(cpu, rq);

    put_prev_task(rq, prev);对当前运行的进程prev，通过调用它所属的类的put_prev_task方法，将当前进程放入运行队列的合适位置。
    next = pick_next_task(rq);//挑选一个优先级最高的任务将其排进队列。  
    clear_tsk_need_resched(prev); //清除prev(被调度出去的进程)的TIF_NEED_RESCHED标志。 
    rq->skip_clock_update = 0;

    if (likely(prev != next)) {
        rq->nr_switches++;
        rq->curr = next;		//rq->curr指针只想下一个要运行的进程实例
        ++*switch_count;

        context_switch(rq, prev, next); /* unlocks the rq */   //进程之间上下文切换  
        /*
         * The context switch have flipped the stack from under us
         * and restored the local variables which were saved when
         * this task called schedule() in the past. prev == current
         * is still correct, but it can be moved to another cpu/rq.
         */
        cpu = smp_processor_id();
        rq = cpu_rq(cpu);
    } else
        raw_spin_unlock_irq(&rq->lock);

    post_schedule(rq);

    preempt_enable_no_resched();
    if (need_resched())
        goto need_resched;
}





























































































































